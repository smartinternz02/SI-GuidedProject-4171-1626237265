{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8563f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3155d",
   "metadata": {},
   "source": [
    "1.importing the libraries\n",
    "\n",
    "2.reading the dataset checking for missing values\n",
    "\n",
    "3.handling missing vales\n",
    "\n",
    "4.splitting data to input and out put\n",
    "\n",
    "5.handle categorical data\n",
    "\n",
    "6.split the data to train and test\n",
    "\n",
    "7.apply feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ff6b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"E:\\\\Externship Project\\\\Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bf1f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research  \\\n",
       "0        337          118                  4  4.5  4.5  9.65         1   \n",
       "1        324          107                  4  4.0  4.5  8.87         1   \n",
       "2        316          104                  3  3.0  3.5  8.00         1   \n",
       "3        322          110                  3  3.5  2.5  8.67         1   \n",
       "4        314          103                  2  2.0  3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit  \n",
       "0             0.92  \n",
       "1             0.76  \n",
       "2             0.72  \n",
       "3             0.80  \n",
       "4             0.65  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29b15a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           False\n",
       "GRE Score            False\n",
       "TOEFL Score          False\n",
       "University Rating    False\n",
       "SOP                  False\n",
       "LOR                  False\n",
       "CGPA                 False\n",
       "Research             False\n",
       "Chance of Admit      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4483080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are no Null values present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f3963ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,0:8].values\n",
    "y = dataset.iloc[:,8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dda0ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  , 337.  , 118.  , ...,   4.5 ,   9.65,   1.  ],\n",
       "       [  2.  , 324.  , 107.  , ...,   4.5 ,   8.87,   1.  ],\n",
       "       [  3.  , 316.  , 104.  , ...,   3.5 ,   8.  ,   1.  ],\n",
       "       ...,\n",
       "       [398.  , 330.  , 116.  , ...,   4.5 ,   9.45,   1.  ],\n",
       "       [399.  , 312.  , 103.  , ...,   4.  ,   8.78,   0.  ],\n",
       "       [400.  , 333.  , 117.  , ...,   4.  ,   9.66,   1.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f1a5977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92, 0.76, 0.72, 0.8 , 0.65, 0.9 , 0.75, 0.68, 0.5 , 0.45, 0.52,\n",
       "       0.84, 0.78, 0.62, 0.61, 0.54, 0.66, 0.65, 0.63, 0.62, 0.64, 0.7 ,\n",
       "       0.94, 0.95, 0.97, 0.94, 0.76, 0.44, 0.46, 0.54, 0.65, 0.74, 0.91,\n",
       "       0.9 , 0.94, 0.88, 0.64, 0.58, 0.52, 0.48, 0.46, 0.49, 0.53, 0.87,\n",
       "       0.91, 0.88, 0.86, 0.89, 0.82, 0.78, 0.76, 0.56, 0.78, 0.72, 0.7 ,\n",
       "       0.64, 0.64, 0.46, 0.36, 0.42, 0.48, 0.47, 0.54, 0.56, 0.52, 0.55,\n",
       "       0.61, 0.57, 0.68, 0.78, 0.94, 0.96, 0.93, 0.84, 0.74, 0.72, 0.74,\n",
       "       0.64, 0.44, 0.46, 0.5 , 0.96, 0.92, 0.92, 0.94, 0.76, 0.72, 0.66,\n",
       "       0.64, 0.74, 0.64, 0.38, 0.34, 0.44, 0.36, 0.42, 0.48, 0.86, 0.9 ,\n",
       "       0.79, 0.71, 0.64, 0.62, 0.57, 0.74, 0.69, 0.87, 0.91, 0.93, 0.68,\n",
       "       0.61, 0.69, 0.62, 0.72, 0.59, 0.66, 0.56, 0.45, 0.47, 0.71, 0.94,\n",
       "       0.94, 0.57, 0.61, 0.57, 0.64, 0.85, 0.78, 0.84, 0.92, 0.96, 0.77,\n",
       "       0.71, 0.79, 0.89, 0.82, 0.76, 0.71, 0.8 , 0.78, 0.84, 0.9 , 0.92,\n",
       "       0.97, 0.8 , 0.81, 0.75, 0.83, 0.96, 0.79, 0.93, 0.94, 0.86, 0.79,\n",
       "       0.8 , 0.77, 0.7 , 0.65, 0.61, 0.52, 0.57, 0.53, 0.67, 0.68, 0.81,\n",
       "       0.78, 0.65, 0.64, 0.64, 0.65, 0.68, 0.89, 0.86, 0.89, 0.87, 0.85,\n",
       "       0.9 , 0.82, 0.72, 0.73, 0.71, 0.71, 0.68, 0.75, 0.72, 0.89, 0.84,\n",
       "       0.93, 0.93, 0.88, 0.9 , 0.87, 0.86, 0.94, 0.77, 0.78, 0.73, 0.73,\n",
       "       0.7 , 0.72, 0.73, 0.72, 0.97, 0.97, 0.69, 0.57, 0.63, 0.66, 0.64,\n",
       "       0.68, 0.79, 0.82, 0.95, 0.96, 0.94, 0.93, 0.91, 0.85, 0.84, 0.74,\n",
       "       0.76, 0.75, 0.76, 0.71, 0.67, 0.61, 0.63, 0.64, 0.71, 0.82, 0.73,\n",
       "       0.74, 0.69, 0.64, 0.91, 0.88, 0.85, 0.86, 0.7 , 0.59, 0.6 , 0.65,\n",
       "       0.7 , 0.76, 0.63, 0.81, 0.72, 0.71, 0.8 , 0.77, 0.74, 0.7 , 0.71,\n",
       "       0.93, 0.85, 0.79, 0.76, 0.78, 0.77, 0.9 , 0.87, 0.71, 0.7 , 0.7 ,\n",
       "       0.75, 0.71, 0.72, 0.73, 0.83, 0.77, 0.72, 0.54, 0.49, 0.52, 0.58,\n",
       "       0.78, 0.89, 0.7 , 0.66, 0.67, 0.68, 0.8 , 0.81, 0.8 , 0.94, 0.93,\n",
       "       0.92, 0.89, 0.82, 0.79, 0.58, 0.56, 0.56, 0.64, 0.61, 0.68, 0.76,\n",
       "       0.86, 0.9 , 0.71, 0.62, 0.66, 0.65, 0.73, 0.62, 0.74, 0.79, 0.8 ,\n",
       "       0.69, 0.7 , 0.76, 0.84, 0.78, 0.67, 0.66, 0.65, 0.54, 0.58, 0.79,\n",
       "       0.8 , 0.75, 0.73, 0.72, 0.62, 0.67, 0.81, 0.63, 0.69, 0.8 , 0.43,\n",
       "       0.8 , 0.73, 0.75, 0.71, 0.73, 0.83, 0.72, 0.94, 0.81, 0.81, 0.75,\n",
       "       0.79, 0.58, 0.59, 0.47, 0.49, 0.47, 0.42, 0.57, 0.62, 0.74, 0.73,\n",
       "       0.64, 0.63, 0.59, 0.73, 0.79, 0.68, 0.7 , 0.81, 0.85, 0.93, 0.91,\n",
       "       0.69, 0.77, 0.86, 0.74, 0.57, 0.51, 0.67, 0.72, 0.89, 0.95, 0.79,\n",
       "       0.39, 0.38, 0.34, 0.47, 0.56, 0.71, 0.78, 0.73, 0.82, 0.62, 0.96,\n",
       "       0.96, 0.46, 0.53, 0.49, 0.76, 0.64, 0.71, 0.84, 0.77, 0.89, 0.82,\n",
       "       0.84, 0.91, 0.67, 0.95])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "291110ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two columns also have an added space in the label which we'll take out\n",
    "dataset.rename(columns = {'Chance of Admit ':'Chance of Admit', 'LOR ':'LOR'}, inplace=True)\n",
    "dataset.drop(labels='Serial No.', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa9b467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research  \\\n",
       "0          337          118                  4  4.5  4.5  9.65         1   \n",
       "1          324          107                  4  4.0  4.5  8.87         1   \n",
       "2          316          104                  3  3.0  3.5  8.00         1   \n",
       "3          322          110                  3  3.5  2.5  8.67         1   \n",
       "4          314          103                  2  2.0  3.0  8.21         0   \n",
       "..         ...          ...                ...  ...  ...   ...       ...   \n",
       "395        324          110                  3  3.5  3.5  9.04         1   \n",
       "396        325          107                  3  3.0  3.5  9.11         1   \n",
       "397        330          116                  4  5.0  4.5  9.45         1   \n",
       "398        312          103                  3  3.5  4.0  8.78         0   \n",
       "399        333          117                  4  5.0  4.0  9.66         1   \n",
       "\n",
       "     Chance of Admit  \n",
       "0               0.92  \n",
       "1               0.76  \n",
       "2               0.72  \n",
       "3               0.80  \n",
       "4               0.65  \n",
       "..               ...  \n",
       "395             0.82  \n",
       "396             0.84  \n",
       "397             0.91  \n",
       "398             0.67  \n",
       "399             0.95  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9bfa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8af8a384",
   "metadata": {},
   "source": [
    "MULTILINEAR REGRESSION\n",
    "\n",
    "Multiple linear regression is used to estimate the relationship between two or more independent variables and one dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab5427ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test =  train_test_split(x,y,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47508e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "588d541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = mlr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f1c07a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69274573, 0.7162844 , 0.79941252, 0.61382844, 0.72412844,\n",
       "       0.57724345, 0.69870221, 0.65305302, 0.85967181, 0.92208853,\n",
       "       0.50741235, 0.87777388, 0.69576844, 0.48003146, 0.82596866,\n",
       "       0.59565583, 0.63612398, 0.79850128, 0.58499028, 0.7307459 ,\n",
       "       0.8786028 , 0.8559767 , 0.64900472, 0.47743531, 0.78607991,\n",
       "       0.60253488, 0.48121579, 0.61628425, 0.91027272, 0.63613885,\n",
       "       0.63020528, 0.7557007 , 0.76839541, 0.5561474 , 0.76461587,\n",
       "       0.75237249, 0.63895412, 0.85786512, 0.62587771, 0.96140491,\n",
       "       0.71247318, 0.68578127, 0.68249048, 0.77665142, 0.84269291,\n",
       "       0.63840207, 0.59141106, 0.70924876, 0.5980027 , 0.60045941,\n",
       "       0.67382167, 0.78571075, 0.65927066, 0.8826041 , 0.73344715,\n",
       "       0.77032863, 0.70188829, 0.70511474, 0.73998397, 0.81268997,\n",
       "       0.74512167, 0.47570513, 0.60011772, 0.5445201 , 0.84399797,\n",
       "       0.84187797, 0.72356766, 0.84411964, 0.75646874, 0.76426218,\n",
       "       0.56701231, 0.84379017, 0.80029522, 0.58786428, 0.915287  ,\n",
       "       0.61009641, 0.65539763, 0.65692288, 0.93229797, 0.53046687])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33b049da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71, 0.7 , 0.79, 0.73, 0.72, 0.48, 0.77, 0.71, 0.9 , 0.94, 0.58,\n",
       "       0.89, 0.72, 0.57, 0.78, 0.42, 0.64, 0.84, 0.63, 0.72, 0.9 , 0.83,\n",
       "       0.57, 0.47, 0.85, 0.67, 0.44, 0.54, 0.92, 0.62, 0.68, 0.73, 0.73,\n",
       "       0.61, 0.55, 0.74, 0.64, 0.89, 0.73, 0.95, 0.71, 0.72, 0.75, 0.76,\n",
       "       0.86, 0.7 , 0.39, 0.79, 0.61, 0.64, 0.71, 0.8 , 0.61, 0.89, 0.68,\n",
       "       0.79, 0.78, 0.52, 0.76, 0.88, 0.74, 0.49, 0.65, 0.59, 0.87, 0.89,\n",
       "       0.81, 0.9 , 0.8 , 0.76, 0.68, 0.87, 0.68, 0.64, 0.91, 0.61, 0.69,\n",
       "       0.62, 0.93, 0.43])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce77967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "accuracy = r2_score(ypred,y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3b9b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.08642623835436"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54a29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90d7a17a",
   "metadata": {},
   "source": [
    "DECISION TREE\n",
    "\n",
    "A decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails) , each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6faffe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.16323192689579"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dec_tree = DecisionTreeRegressor(random_state=0, max_depth=6)\n",
    "dec_tree.fit(x_train, y_train)\n",
    "y_predict = dec_tree.predict(x_test)\n",
    "dec_tree_score = (dec_tree.score(x_test, y_test))*100\n",
    "dec_tree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1582fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7572d2c",
   "metadata": {},
   "source": [
    "RANDOM FOREST\n",
    "\n",
    "Random forest algorithm creates decision trees on data samples and then gets the prediction from each of them and finally selects the best solution by means of voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "310853fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.5528221329573"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators=110,max_depth=6,random_state=0)\n",
    "forest.fit(x_train, y_train)\n",
    "y_predict = forest.predict(x_test)\n",
    "forest_score = (forest.score(x_test, y_test))*100\n",
    "forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e09d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea6397c8",
   "metadata": {},
   "source": [
    "COMPARISION OF ACCURACIES OF MULTILINEAR REGRESSION , DECISION TREE , RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "942e6f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuhya\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Methods = ['mlr', 'Decision Trees', 'Random Forests']\n",
    "Scores = np.array([accuracy, dec_tree_score, forest_score])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.barplot(Methods, Scores)\n",
    "plt.title('Algorithm Prediction Accuracies')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1895adf",
   "metadata": {},
   "source": [
    "CONCLUSION\n",
    "\n",
    "By the above comparison among Multilinear regression, Decision Tree and Random Forest, the Random Forest Model has more Accuracy i.e., 0.7449517422419814. The best model for this Dataset for \"UNIVERSITY ADMISSION PREDICTION\" is \"RANDOM FOREST\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f120b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
